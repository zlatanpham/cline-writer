```yaml
title: Everyone has something to hide
author: Paul Jarvis
tags:
  - privacy
  - digital privacy
  - social cooling
  - data protection
  - surveillance
  - government
  - big tech
```

In this article, I will explain why everyone should care about their privacy, not just privacy nerds like me.

Whenever I write or tweet about privacy, I tend to get a whack of replies calling me a tinfoil hat nutter and explaining that normal, law-abiding citizens shouldn’t care about privacy because they have nothing to hide.

While I understand this line of reasoning (“if you’re not doing anything wrong, you should have nothing to hide), it’s both uninformed and dangerous.

A while back, [Manoush Zomorodi](https://twitter.com/manoushz) interviewed Elan Gale (executive producer of The Bachelor TV show) on the [Privacy Paradox podcast](https://project.wnyc.org/privacy-paradox) about how we always try to curate our perceived selves when we know someone else is watching.

Researchers have coined the term “[social cooling](https://www.socialcooling.com/)” to describe what happens when we feel like we are constantly being watched, even if we are doing nothing wrong. The vast amount of data being collected about us at all times online supercharges this and makes us question and self-limit our desire to take risks or exercise free speech. Long term, these effects “chill” or “cool down” society as a whole. This is also backed up by [a study](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2769645) looking at online surveillance and Wikipedia use.

Here’s how social cooling works
-------------------------------

1.  Since all of our data is constantly being watched, collected, mined and stored, it’s then turned into different scores and data points about our ideas, tastes, preferences and emotions. Data Brokers then compare our scores to other people they have data on, to guess the likelihood of our preferences.
2.  All of this data and scoring creates a “digital reputation” that could potentially limit our opportunities. For example: if you [return goods](https://apprissretail.com/) to a store, you’ll be at a higher risk of being considered a fraudster. Or if you have undesirable friends on social media, you may [pay more](https://trustingsocial.com/) for a loan.
3.  Because we know we are being graded and judged, based on what we do, how we interact, and what we say online, we then change our behaviour to score higher or better. This creates pressure to not rock the boat with opinions or dissent, and breeds a culture of conformity. We’re less likely to take risks - from doctors not wanting to operate on high risk patients (increasing their mortality score) to not wanting to click links for fear your visit may be logged to having our social media profiles examined when crossing borders.

The long tail of diminished digital privacy
-------------------------------------------

Whether it’s on reality TV or even just social media, we act and speak differently because we know we are being watched. We lose our ability to be authentic or explore our own identity and views because we’re stuck trying to put forward our “best selves” and ensure everyone else that we’re here “for the right reasons”. (Didn’t think I’d ever write a Bachelor-related joke on the Fathom blog? ME NEITHER). Without private spaces it’s harder to connect and explore ideas with others: from just getting to know other people for who they are to bigger things like being able to question the world, society, governments, etc.

Privacy can’t just mean that data is collected and then hopefully never used. A lot of times we’re told that data collected about us is for quality assurance, safekeeping or to help better personalize our experience, etc, etc. But the problem is that collected data has a tendency to be used against us eventually (if it’s monetizable or even just leaked/hacked). Nothing is truly secure, especially online, and data gets breached with increasing regularity—even government data. It’s not a matter of whether data collected about us will be breached or hacked, it’s a matter of when. So having data on us, even if it’s just being “collected and not used”, will be used eventually.

Saying that we should have “nothing to hide” is also a completely privileged statement and view as well—for those of us lucky enough to live in currently-democratic countries. Minorities need privacy to shield themselves from social and government repercussions. Those with different sexual orientations, religious minorities, and even folks who just question political leaders in places where it’s illegal require a great deal of privacy for safety. Without privacy, a nefarious government could round up anyone who votes for the opposition (which has happened). The right to keep our views and personal lives private is important because governments have a tendency to change, sometimes not for the better.

As citizens, we need protection from corporations too. A few years ago it was technically possible on Facebook to [target housing ads solely at white people](https://www.cbsnews.com/news/hud-charges-facebook-targeted-ads-enabled-housing-bias/) (filtering out BIPOC). While that’s completely illegal in the US, it was still possible to do on Facebook, using data they had collected about their users.

Why you need to protect your digital privacy
--------------------------------------------

In a democratic society, we should have rights that protect us from our governments knowing everything about our lives and views. Fortunately, in democratic countries, if law enforcement or a government agency wants to enter your house, root through your things, or investigate your digital footprint, they need a warrant from a neutral judge. Yet, if private companies like Facebook or Google want to take our data and personal “effects” (what we do or say online), they just take it through our consent (signed over in lengthy and confusing “Terms of Service” legal docs), use it and have it, without much fuss. It’s important here to note that there is a small difference between governments and big tech companies gathering our data, in so much as governments have things like prisons, guns and death penalties. So while it’s bad that corporations take and use our data without cause, the repercussions aren’t yet as dire as governments doing the same.

The argument is often made that we need to give up some privacy for safety. Like searches at airport security prior to boarding planes or answering questions at a border before being allowed entry. And to be clear, a case for privacy doesn’t mean absolute privacy (you can go live off the grid in the woods for that). Those searches and questions even seem quite reasonable to most people, myself included. But I do think we should get a say or option, or most importantly, some knowledge, when our digital privacy rights are eroded. Most of the time, we are unaware of what’s being tracked, and by whom.

Governments especially love to use ne’er-do-wells and evil-doers, hell bent on destroying the world as we know it, as a reason to weaken privacy laws. And, as I said, sometimes it makes sense to opt into giving up some privacy for the sake of the general good. The problem is that when governments push for weaker privacy rules to combat evil, they backslide into using the new lack of privacy for unrelated things.

Privacy of our ideas, data and places is a fundamental human right and should be determined by the people. Not by what governments tell us can be private, not by tech companies telling us they care about privacy and then selling our data to the highest bidder.

Digital privacy is for everyone
-------------------------------

Sure, some of us might feel like we have nothing to hide right now, but we’d also not want to have our personal information published online (like our home address on Reddit or our Social Security Number on the Dark Web or videos of us using the bathroom or having sex posted on social media). Nor should we want people who legitimately want to keep some things private to be forced away from their privacy, sometimes even unknowingly.

The chilling effect of self-censorship, due to a fear of being watched, is nothing new. Orwell wrote about it in 1984 (published on 8 June 1949).

> There was of course no way of knowing whether you were being watched at any given moment. How often, or on what system, the Thought Police plugged in on any individual wire was guesswork. It was even conceivable that they watched everybody all the time. But at any rate they could plug in your wire whenever they wanted to. You have to live — did live, from habit that became instinct — in the assumption that every sound you made was overheard, and, except in darkness, every movement scrutinized.

This all raises several complicated questions:

1.  If we all become more well behaved due to fear, does this make us less human and less sincere in our actions and attitudes?
2.  If creatives no longer dare to be different or share different work, does it undermine our creative economy (which pushes forward progress)?
3.  Does being constantly watched by an unseeing eye impact our ability to evolve and adapt in positive ways?

Public awareness around digital privacy and feeling we should have “nothing to hide” is still quite low. Because the topic can be complicated (involving big tech, governments, activists and more) our perceptions about what needs to be protected, and why, is still in its infancy. When the machinations of big tech or governments judge and rank everything we do, we need to protect the right to make mistakes or have dissenting views.

[Privacy and security](https://usefathom.com/blog/digital-privacy-online-security) aren’t just for those who have nefarious reasons to hide things from others, but for everyone. All “digital privacy” really and truly is the right to be human - flawed, prone to mistakes, and imperfect but willing to adapt and learn. And when our digital privacy is compromised, by big tech or by the government, it affects us all. The “nothing to hide” argument just doesn’t make sense, because we all have some things (not evil things) that we’d rather not be made public.
